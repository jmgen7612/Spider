# #!/usr/bin/env python3# # -*- coding: utf-8 -*-# #@file   :demo1.py# #@time   :2018/5/12 12:11# #@Author :jmgen# #@Version:1.0# #@Desc   :## from urllib import parse# from urllib import request# url = 'http://47.104.150.198:8888/mantis11/login_page.php'# user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'# referer='http://47.104.150.198:8888/'# postdata = {'username' : 'administrator',#            'password' : 'root'}# # data = parse.urlencode(postdata)# data = bytes(parse.urlencode(postdata),encoding="utf8")# req = request.Request(url=url,data=data,method="POST")# # 将user_agent,referer写入头信息# req.add_header('User-Agent',user_agent)# req.add_header('Referer',referer)# response = request.urlopen(req)# html = response.read()# print(html.decode())# from urllib import request# response = request.urlopen("http://www.baidu.com")# print(response.read().decode())# import urllib.request# import urllib.parse## url = 'http://www.baidu.com'# header = {#    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.96 Safari/537.36'# }## request = urllib.request.Request(url, headers=header)# reponse = urllib.request.urlopen(request).read()# print(reponse)# fhandle = open("./baidu.html", "wb")# fhandle.write(reponse)# fhandle.close()## from lxml import etree# import requests,re,csv,chardet# user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'# headers={'User-Agent':user_agent}# r = requests.get('http://seputu.com/',headers=headers)# #使用lxml解析网页## html = etree.HTML(r.text)# div_mulus = html.xpath('.//*[@class="mulu"]')#先找到所有的div class=mulu标签# pattern = re.compile(r'\s*\[(.*)\]\s+(.*)')# rows=[]# for div_mulu in div_mulus:#     #找到所有的div_h2标签#     div_h2 = div_mulu.xpath('./div[@class="mulu-title"]/center/h2/text()')#     if len(div_h2)> 0:#         h2_title = div_h2[0]#         print(type(h2_title))#         a_s = div_mulu.xpath('./div[@class="box"]/ul/li/a')#         for a in a_s:#             #找到href属性#             href=a.xpath('./@href')[0].encode('utf-8')#             #找到title属性#             box_title = a.xpath('./@title')[0]#             pattern = re.compile(r'\s*\[(.*)\]\s+(.*)')#             match = pattern.search(box_title)#             if match!=None:#                 date =match.group(1).encode('utf-8')#                 real_title= match.group(2)#                 # print real_title#                 content=(h2_title,real_title,href,date)#                 print(content)#                 rows.append(content)# headers = ['title','real_title','href','date']# with open('qiye.csv','w') as f:#     f_csv = csv.writer(f,)#     f_csv.writerow(headers)#     f_csv.writerows(rows)# from urllib.request import urlretrieve# from lxml import etree# import requests# def Schedule(blocknum,blocksize,totalsize):#     '''''#     blocknum:已经下载的数据块#     blocksize:数据块的大小#     totalsize:远程文件的大小#     '''#     per = 100.0 * blocknum * blocksize / totalsize#     if per > 100 :#         per = 100#     print('当前下载进度：%d'%per)# user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'# headers={'User-Agent':user_agent}# r = requests.get('http://www.ivsky.com/tupian/ziranfengguang/',headers=headers)# #使用lxml解析网页# html = etree.HTML(r.text)# img_urls = html.xpath('.//img/@src')#先找到所有的img# i=0# for img_url in img_urls:#     urlretrieve(img_url,'img'+str(i)+'.jpg',Schedule)#     i+=1from urllib.parse import urljoinprint(urljoin('http://www.baidu.com', 'FAQ.html'))print(urljoin('http://www.baidu.com', 'https://pythonsite.com/FAQ.html'))print(urljoin('http://www.baidu.com/about.html', 'https://pythonsite.com/FAQ.html'))print(urljoin('http://www.baidu.com/about.html', 'https://pythonsite.com/FAQ.html?question=2'))print(urljoin('http://www.baidu.com?wd=abc', 'https://pythonsite.com/index.php'))print(urljoin('http://www.baidu.com', '?category=2#comment'))print(urljoin('www.baidu.com', '?category=2#comment'))print(urljoin('www.baidu.com#comment', '?category=2'))print(urljoin('http://baike.baidu.com/view/284853.htm', '/item/蜘蛛/8135707'))