#!/usr/bin/env python3# -*- coding: utf-8 -*-#@file   :SpiderMan.py#@time   :2018/5/26 2:04#@Author :jmgen#@Version:1.0#@Desc   :from LagouSpider.wayThree.HtmlParser import HtmlParserfrom LagouSpider.wayThree.DataOutput import DataOutputclass SpiderMan(object):    def __init__(self):        self.parser = HtmlParser()        self.output = DataOutput()    def getlen(self,request_url,page_num,keywords,baseurl,params,headers):        datas = self.parser.get_datas(request_url, page_num,keywords, baseurl, params, headers)        return len(datas)    def crawl(self,temp,request_url,page_num,keywords,baseurl,params,headers):        datas = self.parser.get_datas(request_url,page_num,keywords,baseurl,params,headers)        try:            self.output.store_datas(datas)            self.output.output_file(datas)            temp = self.output.writeExcel(temp, datas)        except  Exception:            print("Crawl failed")        return tempif __name__=="__main__":    page_num=1    keywords="测试工程师"    params = {        'px': 'default',        'yx': '15k-25k',        'city': '深圳',        'district': '南山区',        'bizArea': '科技园',        'needAddtionalResult': False    }    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0',        'Connection': 'keep-alive',        'Host': 'www.lagou.com',        'Origin': 'https://www.lagou.com',        'Cookie': 'JSESSIONID=ABAAABAAAGGABCB3695C31A710229B73200AB551E0288B0; _ga=GA1.2.1913932621.1527268687; _gid=GA1.2.1394737526.1527268687; user_trace_token=20180526011844-ad402ed4-603f-11e8-9e48-525400f775ce; LGUID=20180526011844-ad4032f3-603f-11e8-9e48-525400f775ce; index_location_city=%E6%B7%B1%E5%9C%B3; X_HTTP_TOKEN=323927b0a27d300fb0aea4843ae52ab8; ab_test_random_num=0; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1527268687,1527268702,1527313955; SEARCH_ID=79f4dc43d8744c20b521cb83aa005859; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1527314039; LGRID=20180526135436-4564cdd0-60a9-11e8-9f0b-525400f775ce; TG-TRACK-CODE=jobs_code',        'Accept': 'application/json, text/javascript, */*; q=0.01',        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',        'Referer': 'https://www.lagou.com/jobs/list_%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98?labelWords=&fromSearch=true&suginput=',        'X-Anit-Forge-Token': 'None',        'X-Requested-With': 'XMLHttpRequest'    }    request_url="https://www.lagou.com/jobs/positionAjax.json"    baseurl="https://www.lagou.com/jobs/"    print("开始")    temp=2    spider_man = SpiderMan()    # spider_man.crawl(request_url, page_num, keywords, baseurl, params, headers)    while True:        print("正在爬取第" + str(page_num) + "页......")        print(str(temp) + "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@")        temp=spider_man.crawl(temp,request_url, page_num, keywords, baseurl, params, headers)        print(str(temp) + "###################################")        resultlen = spider_man.getlen(request_url, page_num, keywords, baseurl, params, headers)        if (resultlen > 0):            page_num += 1        else:            spider_man.output.closeExcel()            print("已经是最后一页了")            break    print("爬取完成")